# Kaggle - House Prices: Advanced Regression Techniques

![Python](https://img.shields.io/badge/python-3.x-orange.svg)
![Type](https://img.shields.io/badge/Machine-Learning-red.svg)
[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/jithinharidaas.svg?style=social&label=Follow%20%40jithinharidaas)](https://twitter.com/jithinharidaas)


With 79 explanatory variables describing almost every aspect of residential homes in Ames, Iowa, this 
competition challenges the data science community to predict the final price of each home.


### Data
train.csv: 1460 houses with 81 attributes, including the labels (sale prices)<br>
test.csv: 1459 houses with 80 attributes<br>
data_description.txt: full description of each column of the csv files

### Results
Feature engineering and a solution using XGBoost regression are shown in [Exploring-HousePrice-Dataset.ipynb](2020-08-15-Exploring-HousePrice-Dataset.ipynb).

### Required libraries
- ``NumPy``
- ``Pandas``
- ``scikit-learn``
- ``scipy``
- ``seaborn``
- ``matplotlib``
- ``XGBoost``

### Reference
[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

## Team
- [Jithin K Haridas](https://github.com/jithinharidas)
- [Satyak C](https://github.com/satyak3)
